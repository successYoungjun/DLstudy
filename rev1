import tensorflow as tf
import numpy as np
from tensorflow.examples.tutorials.mnist import input_data

batch_size = 128
test_size = 256

def init_weights(shape):
    return tf.Variable(tf.random_normal(shape, stddev=0.01))

def init_bias(shape):
    return tf.Variable(tf.random_normal(shape, stddev=0.01))

def conv2d(x, W):
    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')

def max_pool_2by2(x):
    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')

#CCN model
def cnn_usr(trX):
    ## 1st conv layer
    W_conv1 = init_weights([3, 3, 1, 32])  # 3x3x1 conv, 32 outputs
    b_conv1 = init_bias([32])
    r_conv1 = tf.nn.relu(conv2d(trX, W_conv1) + b_conv1)
    # 1st pooling
    r_pool1 = max_pool_2by2(r_conv1)

    ## 2nd conv layer
    W_conv2 = init_weights([3, 3, 32, 64])  # 3x3x1 conv, 64 outputs
    b_conv2 = init_bias([64])
    r_conv2 = tf.nn.relu(conv2d(r_pool1, W_conv2) + b_conv2)
    # 2nd pooling
    r_pool2 = max_pool_2by2(r_conv2)

    ## 3rd conv layer
    W_conv3 = init_weights([3, 3, 64, 128])  # 3x3x1 conv, 128 outputs
    b_conv3 = init_bias([128])
    r_conv3 = tf.nn.relu(conv2d(r_pool2, W_conv3) + b_conv3)
    # 3rd pooling
    r_pool3 = max_pool_2by2(r_conv3)

    ## Fully connected layer 1
    W_fc1 = init_weights([128 * 4 * 4, 625])
    b_fc1 = init_bias([625])

    r_pool3_1d = tf.reshape(r_pool3, [-1, 128 * 4 * 4])
    r_fc1 = tf.nn.relu(tf.matmul(r_pool3_1d, W_fc1) + b_fc1)

    p_keep_hidden = tf.placeholder("float")
    r_fc1_drop = tf.nn.dropout(r_fc1, p_keep_hidden)

    ## Fully connected layer 2
    W_fc2 = init_weights([625, 10])
    b_fc2 = init_bias([10])

    py_x = tf.matmul(r_fc1_drop, W_fc2) + b_fc2

return py_x

# import images
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels
trX = trX.reshape(-1, 28, 28, 1)  # 28x28x1 input img
teX = teX.reshape(-1, 28, 28, 1)  # 28x28x1 input img

py_x = cnn_usr(trX)
